# -*- coding: utf-8 -*-
"""NORMALIZATION_MNIST_sv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sl9WUQ4OTOD8gzmOpuIgtyYjFSXJtTI1
"""

import flwr as fl
from flwr.common import Metrics
from flwr.common.typing import Scalar
from collections import OrderedDict
from typing import List, Tuple, Dict, Optional

from norms import *
from utils import *

import numpy as np
import csv
import tensorflow as tf

from flwr.simulation.ray_transport.utils import enable_tf_gpu_growth
from skew import *

#os.environ["CUDA_VISIBLE_DEVICES"]="0,1"
enable_tf_gpu_growth()


"""# Global Constants (Dataset Specific)"""
# global variables
BATCH_SIZE = 8
EPOCH = 250
LEARNING_RATE = 0.001
NORMALIZATION_LAYER = ''
NUM_CLIENTS = 10
#NORMALIZATION_TYPE = ''
EARLY_STOPPING_PATIENCE = 20
DATASET_INPUT_SHAPE = (31,1)
IS_IMAGE_DATA = False

X_trains_fed = np.zeros(1)
Y_trains_fed = np.zeros(1)
X_test_fed = np.zeros(1) # test sets are not actually splitted but we use it as a variable array
Y_test_fed = np.zeros(1)
X_val_fed = np.zeros(1)
Y_val_fed = np.zeros(1)


"""# Dataset Retrieval"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score


def load_data(data_dir=""):
    # Load X data
    with open(f"{data_dir}x.csv", mode='r') as file:
        reader = csv.reader(file)
        x_data = np.array(list(reader), dtype=float)

    # Load Y data
    with open(f"{data_dir}y.csv", mode='r') as file:
        reader = csv.reader(file)
        y_data = np.array(list(reader), dtype=float)

    # Split data into training, testing, and validation sets
    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, shuffle=True, random_state=42)
    x_train, x_vals, y_train, y_vals = train_test_split(x_train, y_train, test_size=0.1, random_state=42)

    global X_trains_fed
    global Y_trains_fed
    global X_test_fed
    global Y_test_fed
    global X_val_fed
    global Y_val_fed

    X_trains_fed = x_train
    Y_trains_fed = y_train
    X_test_fed = x_test
    Y_test_fed = y_test
    X_val_fed = x_vals
    Y_val_fed = y_vals

    return


def do_skew(skew_type, num_clients, X_data, Y_data):
    if(skew_type == 'feature_0.3'):
      clientsData, clientsDataLabels = feature_skew_dist(X_data,  Y_data,num_clients, sigma = 0.3, batch_size=BATCH_SIZE)
    elif(skew_type == 'feature_0.7'):
      clientsData, clientsDataLabels = feature_skew_dist(X_data,  Y_data,num_clients, sigma = 0.7, batch_size=BATCH_SIZE)
    elif(skew_type == 'label_5.0'):
      clientsData, clientsDataLabels = label_skew_dist(X_data,  Y_data,num_clients, 2, beta = 5, batch_size=BATCH_SIZE)
    elif(skew_type == 'label_0.5'):
      clientsData, clientsDataLabels = label_skew_dist(X_data,  Y_data,num_clients, 2, beta = 0.5, batch_size=BATCH_SIZE)
    elif(skew_type == 'quantity_5.0'):
      clientsData, clientsDataLabels = qty_skew_dist(X_data,  Y_data,num_clients, beta = 5, batch_size=BATCH_SIZE)
    elif(skew_type == 'quantity_0.7'):
      clientsData, clientsDataLabels = qty_skew_dist(X_data,  Y_data,num_clients, beta = 0.7, batch_size=BATCH_SIZE)
    elif(skew_type == 'default'):
        clientsData, clientsDataLabels = iid_dist(X_data, Y_data, num_clients, batch_size=BATCH_SIZE)
    else:
        print('error')



    return clientsData, clientsDataLabels

"""# Normalization Methods"""

def do_normalization(normalization_type, num_clients, X_data, val_x, test_x, Y_data, val_y, test_y):

    global NORMALIZATION_LAYER

    NORMALIZATION_LAYER = 'default'

    if normalization_type == 'batch_norm':
        NORMALIZATION_LAYER = 'batch_norm'
    elif normalization_type == 'layer_norm':
        NORMALIZATION_LAYER = 'layer_norm'
    elif normalization_type == 'instance_norm':
        NORMALIZATION_LAYER = 'instance_norm'
    elif normalization_type == 'group_norm':
        NORMALIZATION_LAYER = 'group_norm'
    elif normalization_type == 'local_box_cox':
        for i in range(num_clients):
            print(i)
            X_data[i] = box_cox(X_data[i],val_x[i],test_x[i])

    elif normalization_type == 'local_yeo_johnson':
        for i in range(num_clients):
            X_data[i], val_x[i], test_x[i] = yeo_johnson(X_data[i], val_x[i], test_x[i])

    elif normalization_type == 'local_min_max':
        for i in range(num_clients):
            X_data[i], val_x[i], test_x[i] = min_max(X_data[i], val_x[i], test_x[i])

    elif normalization_type == 'local_z_score':
        for i in range(num_clients):
            X_data[i], val_x[i], test_x[i] = z_score(X_data[i], val_x[i], test_x[i])

    elif normalization_type == 'log_scaling':
        for i in range(num_clients):
            X_data[i], val_x[i], test_x[i] = log_scaling(X_data[i], val_x[i], test_x[i])

    elif normalization_type == 'local_robust_scaling':
        for i in range(num_clients):
            X_data[i], val_x[i], test_x[i] = robust_scaling(X_data[i], val_x[i], test_x[i])

    elif normalization_type == 'global_z_score':
        merged_train = merge(X_data)
        merged_val = merge(val_x)
        merged_test = merge(test_x)

        merget_train_y = merge(Y_data)
        merged_val_y = merge(val_y)
        merged_test_y = merge(test_y)

        merged_train, merged_val, merged_test = z_score(merged_train, merged_val, merged_test)

        X_data, Y_data = split(X_data, merged_train, merget_train_y)
        val_x, val_y = split(val_x, merged_val, merged_val_y)
        test_x, test_y = split(test_x, merged_test, merged_test_y)

    elif normalization_type == 'global_min_max':
        merged_train = merge(X_data)
        merged_val = merge(val_x)
        merged_test = merge(test_x)

        merget_train_y = merge(Y_data)
        merged_val_y = merge(val_y)
        merged_test_y = merge(test_y)

        merged_train, merged_val, merged_test = min_max(merged_train, merged_val, merged_test)

        X_data, Y_data = split(X_data, merged_train, merget_train_y)
        val_x, val_y = split(val_x, merged_val, merged_val_y)
        test_x, test_y = split(test_x, merged_test, merged_test_y)

    elif normalization_type == 'global_box_cox':
        merged_train = merge(X_data)
        merged_val = merge(val_x)
        merged_test = merge(test_x)

        merget_train_y = merge(Y_data)
        merged_val_y = merge(val_y)
        merged_test_y = merge(test_y)

        merged_train, merged_val, merged_test = box_cox(merged_train, merged_val, merged_test)

        X_data, Y_data = split(X_data, merged_train, merget_train_y)
        val_x, val_y = split(val_x, merged_val, merged_val_y)
        test_x, test_y = split(test_x, merged_test, merged_test_y)

    elif normalization_type == 'global_robust_scaling':
        merged_train = merge(X_data)
        merged_val = merge(val_x)
        merged_test = merge(test_x)

        merget_train_y = merge(Y_data)
        merged_val_y = merge(val_y)
        merged_test_y = merge(test_y)

        merged_train, merged_val, merged_test = robust_scaling(merged_train, merged_val, merged_test)

        X_data, Y_data = split(X_data, merged_train, merget_train_y)
        val_x, val_y = split(val_x, merged_val, merged_val_y)
        test_x, test_y = split(test_x, merged_test, merged_test_y)

    elif normalization_type == 'global_yeo_johnson':
        merged_train = merge(X_data)
        merged_val = merge(val_x)
        merged_test = merge(test_x)

        merget_train_y = merge(Y_data)
        merged_val_y = merge(val_y)
        merged_test_y = merge(test_y)
        merged_train, merged_val, merged_test = yeo_johnson(merged_train, merged_val, merged_test)

        X_data, Y_data = split(X_data, merged_train, merget_train_y)
        val_x, val_y = split(val_x, merged_val, merged_val_y)
        test_x, test_y = split(test_x, merged_test, merged_test_y)

    elif normalization_type == 'default':
        pass  # default case

    else:
        print("error")

    return X_data, val_x, test_x, Y_data, val_y, test_y

"""# Network Model (Dataset Specific)"""


def get_model():    
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(units=128, activation='relu'))
    
    if NORMALIZATION_LAYER == 'batch_norm':
        model.add(tf.keras.layers.BatchNormalization())
    elif NORMALIZATION_LAYER == 'instance_norm':
        model.add(tf.keras.layers.GroupNormalization(groups=1))
    elif NORMALIZATION_LAYER == 'group_norm':
        model.add(tf.keras.layers.GroupNormalization(groups=4))
    elif NORMALIZATION_LAYER == 'layer_norm':
        model.add(tf.keras.layers.LayerNormalization())

    model.add(tf.keras.layers.Dropout(0.2))
    model.add(tf.keras.layers.Dense(units=64, activation='relu'))
    model.add(tf.keras.layers.Dropout(0.2))
    model.add(tf.keras.layers.Dense(units=32, activation='relu'))
    model.add(tf.keras.layers.Dropout(0.2))
    model.add(tf.keras.layers.Dense(units=16, activation='relu'))
    model.add(tf.keras.layers.Dense(units=2))
    return model

"""# Flower Client (Dataset Specific)"""

from flwr.common.typing import NDArrays
class FlowerClient(fl.client.NumPyClient):

    def __init__(self, model: tf.keras.models.Sequential, X_train: np.ndarray, y_train: np.ndarray):
        self.model = model

        self.X_train = X_train
        self.y_train = y_train


    def get_parameters(self, config):
        return self.model.get_weights()


    def fit(self, parameters: NDArrays, config: Dict[str, Scalar]) -> NDArrays:

        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mean_absolute_error')

        self.model.set_weights(parameters)

        history = self.model.fit(self.X_train, self.y_train ,batch_size=BATCH_SIZE, epochs=1, verbose=0)
        y_pred = self.model.predict(self.X_train)
        r2 = r2_score(self.y_train, y_pred)
        results = {
            "loss": history.history["loss"][0],
            "r2": r2
        }
        return self.model.get_weights(), len(self.X_train), results

    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar])-> Tuple[float, int, Dict[str, Scalar]]:
        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mean_absolute_error')
        self.model.set_weights(parameters)

        loss = self.model.evaluate(self.X_train, self.y_train, verbose=0)
        y_pred = self.model.predict(self.X_train)
        r2 = r2_score(self.y_train, y_pred)
        return loss, len(self.X_train), {"r2": r2}

def create_client_fn(cid: str) -> FlowerClient:
    model = get_model()
    cid_int = int(cid)
    return FlowerClient(model, X_trains_fed[cid_int], Y_trains_fed[cid_int])

def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:
    accuracies = [num_examples * m["r2"] for num_examples, m in metrics]
    examples = [num_examples for num_examples, _ in metrics]

    # Aggregate and return custom metric (weighted average)
    return {"r2": sum(accuracies) / sum(examples)}

from flwr.server import Server
from logging import INFO
from flwr.common.logger import log
from flwr.server.history import History
from flwr.server.strategy import Strategy
from flwr.server.client_manager import ClientManager, SimpleClientManager
import timeit

class CustomFlowerServer(Server):
    def __init__(
        self,
        *,
        client_manager: ClientManager,
        strategy: Optional[Strategy] = None,
    ) -> None:
        super().__init__(client_manager=client_manager, strategy=strategy)


    # Override
    def fit(self, num_rounds: int, timeout: Optional[float]) -> History:
        """Run federated averaging for a number of rounds."""
        history = History()

        # Initialize parameters
        log(INFO, "Initializing global parameters")
        self.parameters = self._get_initial_parameters(timeout=timeout)
        log(INFO, "Evaluating initial parameters")
        res = self.strategy.evaluate(0, parameters=self.parameters)
        if res is not None:
            log(
                INFO,
                "initial parameters (loss, other metrics): %s, %s",
                res[0],
                res[1],
            )
            history.add_loss_centralized(server_round=0, loss=res[0])
            history.add_metrics_centralized(server_round=0, metrics=res[1])

        # Run federated learning for num_rounds
        log(INFO, "FL starting")
        start_time = timeit.default_timer()

        # Early Stopping Parameters
        best_loss = float("inf")
        patience_counter = 0
        minimum_delta = 0.001  # Example: require at least 0.001 decrease in loss

        for current_round in range(1, num_rounds + 1):
            # Train model and replace previous global model
            res_fit = self.fit_round(
                server_round=current_round,
                timeout=timeout,
            )
            if res_fit is not None:
                parameters_prime, fit_metrics, _ = res_fit  # fit_metrics_aggregated
                if parameters_prime:
                    self.parameters = parameters_prime
                history.add_metrics_distributed_fit(
                    server_round=current_round, metrics=fit_metrics
                )

            # Evaluate model using strategy implementation
            res_cen = self.strategy.evaluate(current_round, parameters=self.parameters)
            if res_cen is not None:
                loss_cen, metrics_cen = res_cen
                log(
                    INFO,
                    "fit progress: (%s, %s, %s, %s)",
                    current_round,
                    loss_cen,
                    metrics_cen,
                    timeit.default_timer() - start_time,
                )
                history.add_loss_centralized(server_round=current_round, loss=loss_cen)
                history.add_metrics_centralized(
                    server_round=current_round, metrics=metrics_cen
                )

            # Evaluate model on a sample of available clients
            res_fed = self.evaluate_round(server_round=current_round, timeout=timeout)
            if res_fed is not None:
                loss_fed, evaluate_metrics_fed, _ = res_fed
                if loss_fed is not None:
                    history.add_loss_distributed(
                        server_round=current_round, loss=loss_fed
                    )
                    history.add_metrics_distributed(
                        server_round=current_round, metrics=evaluate_metrics_fed
                    )

            if res_cen is not None:
                loss_cen, metrics_cen = res_cen

                # Check for improvement
                if loss_cen < best_loss - minimum_delta:
                    best_loss = loss_cen
                    patience_counter = 0  # Reset counter if improvement
                else:
                    patience_counter += 1

                # Early stopping check
                if patience_counter >= EARLY_STOPPING_PATIENCE:
                    log(INFO, "Early stopping triggered at round %s", current_round)
                    break  # Exit the training loop

        # Bookkeeping
        end_time = timeit.default_timer()
        elapsed = end_time - start_time
        log(INFO, "FL finished in %s", elapsed)
        return history

# Required for early stopping
best_r2 = 0.0
weights = np.array([])
best_loss = float("inf")
minimum_delta = 0.001  # Example: require at least 0.001 decrease in loss

def evaluate(
    server_round: int,
    parameters: fl.common.NDArrays,
    config: Dict[str, fl.common.Scalar],
    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:
    """Centralized evaluation function"""

    model = get_model()
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mean_absolute_error')

    model.set_weights(parameters)

    loss = model.evaluate(X_val_fed, Y_val_fed, batch_size=BATCH_SIZE, verbose=0)
    y_pred = model.predict(X_val_fed)
    r2 = r2_score(Y_test_fed, y_pred)
    
    global best_r2
    global best_loss
    global weights

    print(f"LOSS: {loss}")
    print(f"BEST_LOSS: {best_loss}")
    
    print(f"R2: {r2}")
    print(f"BEST R2: {best_r2}")
    
    print(f"SERVER_ROUND: {server_round}")

    if loss < best_loss - minimum_delta:
        best_r2 = r2
        weights = parameters
        best_loss = loss

    return loss, {"r2": r2}

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
def get_results():
    '''
    At the end of the federated learning process, calculates results and returns
    Test F1 Score
    Test Loss
    Test Accuracy
    Test Precision
    Test Recall
    '''
    global X_test_fed, Y_test_fed, weights

    model = get_model()
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss='mean_absolute_error')
    model.set_weights(weights)
    
    test_loss  = model.evaluate(X_test_fed, Y_test_fed, batch_size=BATCH_SIZE, verbose=0)

    y_pred = model.predict(X_test_fed)
    
    test_mae = mean_absolute_error(Y_test_fed, y_pred)
    test_r2 = r2_score(Y_test_fed, y_pred)

    return test_loss, test_mae, test_r2

def federated_train(x, y, num_clients):

    global X_trains_fed
    global Y_trains_fed
    X_trains_fed = x
    Y_trains_fed = y

    client_resources = {"num_cpus": 2}
    if tf.config.get_visible_devices("GPU"):
        client_resources["num_gpus"] = 1

    # Specify the Strategy
    strategy = fl.server.strategy.FedAvg(
        fraction_fit=1.0,  # Sample 100% of available clients for training
        fraction_evaluate=1.0,
        min_fit_clients=num_clients,
        min_evaluate_clients=num_clients,
        min_available_clients=num_clients,  # Wait until all 8 clients are available
        evaluate_metrics_aggregation_fn=weighted_average,
        evaluate_fn=evaluate
    )

    # Start simulation
    history = fl.simulation.start_simulation(
        client_fn=create_client_fn,
        num_clients=num_clients,
        config=fl.server.ServerConfig(num_rounds=EPOCH),
        server=CustomFlowerServer(client_manager=SimpleClientManager(),
        strategy=strategy
        ),
        client_resources=client_resources,
        actor_kwargs={
            "on_actor_init_fn": enable_tf_gpu_growth  # Enable GPU growth upon actor init
            # does nothing if `num_gpus` in client_resources is 0.0
        },
    )

    test_loss, test_mae, test_r2 = get_results()

    return  history, test_loss, test_mae, test_r2

"""# Training and Saving the Results"""

import wandb

wandb.login()

sweep_config = {
    'method': 'grid'
    }

metric = {
    'name': 'val_loss',
    'goal': 'minimize'
    }

sweep_config['metric'] = metric

parameters_dict = {
    'b_skew': {
          'values': ['default', 'feature_0.3', 'feature_0.7', 'label_5.0', 'label_0.5', 'quantity_5.0', 'quantity_0.7']
        },
    'a_num_clients': {
          'values': [10,20, 30]
        },
    'c_normalization': {
          'values': ['local_z_score', 'local_min_max', 'batch_norm', 'layer_norm', 'group_norm', 'instance_norm', 'local_robust_scaling',
                     'global_z_score', 'global_min_max','global_robust_scaling',
                     'default']
        }
    }

sweep_config['parameters'] = parameters_dict

parameters_dict.update({
    'dataset': {
        'value': 'parcinson'},
    'experiment_run': {
        'value': '1'}
    })

sweep_id = wandb.sweep(sweep_config, project="parcV1")
#sweep_id = "wmd7yn42" # to continue a sweep
import time

def train(config = None):
    with wandb.init(config=config):

        config = wandb.config
        tf.keras.backend.clear_session()

        global NUM_CLIENTS
        global X_test_fed
        global Y_test_fed

        global X_val_fed
        global Y_val_fed


        NUM_CLIENTS = config['a_num_clients']

        load_data()

        clientsData, clientLabels = do_skew(config['b_skew'], config['a_num_clients'], X_trains_fed, Y_trains_fed)
        val_x, val_y = split(clientsData, X_val_fed, Y_val_fed)
        test_x, test_y = split(clientsData, X_test_fed, Y_test_fed)

        #validation and test datasets are normalized with same parameters train dataset is normalized.
        #Data distribution among clients are protected, for local normalization, val and test datasets are normalized with respect to their local train data normalization parameters.
        normalizedData, val_x, test_x, clientLabels, val_y, test_y = do_normalization(config['c_normalization'], config['a_num_clients'], clientsData, val_x, test_x, clientLabels, val_y, test_y)

        X_val_fed = merge(val_x)
        Y_val_fed = merge(val_y)

        X_test_fed = merge(test_x)
        Y_test_fed = merge(test_y)

        t1 = time.perf_counter(), time.process_time()

        history, test_loss, test_mae, test_r2 = federated_train(normalizedData, clientLabels, config['a_num_clients'])

        t2 = time.perf_counter(), time.process_time()

        t = t2[1] - t1[1]

        global best_r2, weights, best_loss


        if (len(history.losses_centralized) == EPOCH + 1):
            early_stopped_epoch = len(history.losses_centralized) - 1
        else:
            early_stopped_epoch = len(history.losses_centralized) - EARLY_STOPPING_PATIENCE - 1

        # Saving the results
        wandb.log({"time": t})
        wandb.log({"stopped_epoch": early_stopped_epoch})
        wandb.log({"test_loss": test_loss})
        wandb.log({"test_r2": test_r2})
        wandb.log({"test_mae": test_mae})
        wandb.log({"validation_loss": best_loss})
        wandb.log({"validation_accuracy": best_r2})


        table = wandb.Table(data=history.losses_distributed, columns=["x", "y"])
        wandb.log(
            {
                "distributed_loss": wandb.plot.line(
                    table, "x", "y", title="Train Set Loss vs Epoch Plot"
                )
            }
        )


        table2 = wandb.Table(data=history.losses_centralized, columns=["x", "y"])
        wandb.log(
            {
                "centralized_loss": wandb.plot.line(
                    table2, "x", "y", title="Validation Set Loss vs Epoch Plot"
                )
            }
        )

        table3 = wandb.Table(data=history.metrics_distributed['accuracy'], columns=["x", "y"])
        wandb.log(
            {
                "distributed_accuracy": wandb.plot.line(
                    table3, "x", "y", title="Train Set Accuracy vs Epoch Plot"
                )
            }
        )

        table4 = wandb.Table(data=history.metrics_centralized['accuracy'], columns=["x", "y"])
        wandb.log(
            {
                "centralized_accuracy": wandb.plot.line(
                    table4, "x", "y", title="Validation Set Accuracy vs Epoch Plot"
                )
            }
        )

        best_r2 = 0.0
        weights = np.array([])
        best_loss = float("inf")


wandb.agent(sweep_id, train)
wandb.agent(sweep_id, project="parcV1", function=train)