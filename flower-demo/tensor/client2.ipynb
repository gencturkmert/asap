{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import utils as ut\n",
    "import numpy as np\n",
    "from typing import Dict, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(8,)),  \n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),  \n",
    "            layers.Dense(1)  \n",
    "        ]\n",
    "    )\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, x_train, y_train, x_test, y_test):\n",
    "        self.model = model\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Train parameters on the locally held training set.\"\"\"\n",
    "\n",
    "        # Update local model parameters\n",
    "        self.model.set_weights(parameters)\n",
    "\n",
    "        # Get hyperparameters for this round\n",
    "        batch_size: int = config[\"batch_size\"]\n",
    "        epochs: int = config[\"local_epochs\"]\n",
    "\n",
    "        # Train the model using hyperparameters from config\n",
    "        history = self.model.fit(\n",
    "            self.x_train,\n",
    "            self.y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2,\n",
    "        )\n",
    "\n",
    "        # Return updated model parameters, number of examples trained, and results\n",
    "        parameters_prime = self.model.get_weights()\n",
    "        num_examples_train = len(self.x_train)\n",
    "        results = {\n",
    "            \"mse\": history.history[\"mse\"][-1],  # Use the last epoch's MSE\n",
    "            \"mae\": history.history[\"mae\"][-1],  # Use the last epoch's MAE\n",
    "            \"val_mse\": history.history[\"val_mse\"][-1],  # Use the last epoch's validation MSE\n",
    "            \"val_mae\": history.history[\"val_mae\"][-1],  # Use the last epoch's validation MAE\n",
    "        }\n",
    "\n",
    "        return parameters_prime, num_examples_train, results\n",
    "\n",
    "    def get_parameters(self):\n",
    "        \"\"\"Get the current parameters of the local model.\"\"\"\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate parameters on the locally held test set.\"\"\"\n",
    "        self.model.set_weights(parameters)\n",
    "        loss = tf.keras.losses.mean_squared_error(self.y_test, self.model.predict(self.x_test)).numpy().mean().item()\n",
    "        mae = tf.keras.metrics.mean_absolute_error(self.y_test, self.model.predict(self.x_test)).numpy().mean().item()\n",
    "        print(\"*************LOSS******************\",loss)\n",
    "        print(\"************MAE********************\",mae)\n",
    "        return loss, len(self.x_train), {\"mae\": mae}\n",
    "\n",
    "    def get_weights(self):\n",
    "        \"\"\"Get the current weights of the local model.\"\"\"\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        \"\"\"Set the weights of the local model.\"\"\"\n",
    "        self.model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-11-23 01:42:44,619 | grpc.py:49 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-11-23 01:42:44,642 | connection.py:42 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-11-23 01:42:44,644 | connection.py:42 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 12ms/step - loss: 4.3664 - mae: 1.7565 - mse: 4.3664 - val_loss: 3.1679 - val_mae: 1.3670 - val_mse: 3.1679\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.9103686809539795\n",
      "************MAE******************** 1.2954483032226562\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.5763 - mae: 0.9289 - mse: 1.5763 - val_loss: 1.2538 - val_mae: 0.9218 - val_mse: 1.2538\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 1.0733 - mae: 0.8488 - mse: 1.0733 - val_loss: 1.1659 - val_mae: 0.8426 - val_mse: 1.1659\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 1.3876734972000122\n",
      "************MAE******************** 0.9221519827842712\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.9569 - mae: 0.7722 - mse: 0.9569 - val_loss: 1.0446 - val_mae: 0.8104 - val_mse: 1.0446\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.8587 - mae: 0.7349 - mse: 0.8587 - val_loss: 0.9421 - val_mae: 0.7567 - val_mse: 0.9421\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 1.494423508644104\n",
      "************MAE******************** 0.9639512300491333\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7530 - mae: 0.6777 - mse: 0.7530 - val_loss: 0.8082 - val_mae: 0.7006 - val_mse: 0.8082\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6549 - mae: 0.6223 - mse: 0.6549 - val_loss: 0.7231 - val_mae: 0.6409 - val_mse: 0.7231\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 1.8109973669052124\n",
      "************MAE******************** 1.0409014225006104\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.0660860538482666\n",
      "************MAE******************** 1.1044645309448242\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5691 - mae: 0.5585 - mse: 0.5691 - val_loss: 0.6801 - val_mae: 0.5906 - val_mse: 0.6801\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5688 - mae: 0.5564 - mse: 0.5688 - val_loss: 0.6859 - val_mae: 0.5872 - val_mse: 0.6859\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.0793609619140625\n",
      "************MAE******************** 1.1045624017715454\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5597 - mae: 0.5542 - mse: 0.5597 - val_loss: 0.6779 - val_mae: 0.5840 - val_mse: 0.6779\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5558 - mae: 0.5498 - mse: 0.5558 - val_loss: 0.6622 - val_mae: 0.5872 - val_mse: 0.6622\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.0867295265197754\n",
      "************MAE******************** 1.1128555536270142\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.5528 - mae: 0.5516 - mse: 0.5528 - val_loss: 0.6658 - val_mae: 0.5818 - val_mse: 0.6658\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5473 - mae: 0.5427 - mse: 0.5473 - val_loss: 0.6529 - val_mae: 0.5882 - val_mse: 0.6529\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.0804426670074463\n",
      "************MAE******************** 1.1065306663513184\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5462 - mae: 0.5461 - mse: 0.5462 - val_loss: 0.6486 - val_mae: 0.5855 - val_mse: 0.6486\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5430 - mae: 0.5420 - mse: 0.5430 - val_loss: 0.6525 - val_mae: 0.5726 - val_mse: 0.6525\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.1066629886627197\n",
      "************MAE******************** 1.1165728569030762\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5356 - mae: 0.5402 - mse: 0.5356 - val_loss: 0.6460 - val_mae: 0.5710 - val_mse: 0.6460\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5320 - mae: 0.5358 - mse: 0.5320 - val_loss: 0.6392 - val_mae: 0.5708 - val_mse: 0.6392\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS******************"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-11-23 01:43:14,809 | connection.py:139 | gRPC channel closed\n",
      "INFO flwr 2023-11-23 01:43:14,810 | app.py:215 | Disconnect and shut down\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.112994909286499\n",
      "************MAE******************** 1.1158357858657837\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = ut.partition_dataset(2,4,1)\n",
    "\n",
    "client = CifarClient(get_model(), x_train, y_train, x_test, y_test)\n",
    "\n",
    "history = fl.client.start_numpy_client(\n",
    "server_address=\"127.0.0.1:8080\",\n",
    "client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-11-23 01:46:01,782 | grpc.py:49 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-11-23 01:46:01,800 | connection.py:42 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-11-23 01:46:01,803 | connection.py:42 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 21ms/step - loss: 0.5422 - mae: 0.5403 - mse: 0.5422 - val_loss: 0.6329 - val_mae: 0.5641 - val_mse: 0.6329\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "*************LOSS****************** 2.0978851318359375\n",
      "************MAE******************** 1.115322470664978\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5216 - mae: 0.5318 - mse: 0.5216 - val_loss: 0.6224 - val_mae: 0.5733 - val_mse: 0.6224\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5184 - mae: 0.5275 - mse: 0.5184 - val_loss: 0.6470 - val_mae: 0.5544 - val_mse: 0.6470\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.1095409393310547\n",
      "************MAE******************** 1.1189020872116089\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5097 - mae: 0.5231 - mse: 0.5097 - val_loss: 0.6149 - val_mae: 0.5507 - val_mse: 0.6149\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5077 - mae: 0.5203 - mse: 0.5077 - val_loss: 0.6050 - val_mae: 0.5661 - val_mse: 0.6050\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.103264808654785\n",
      "************MAE******************** 1.1168915033340454\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.119640588760376\n",
      "************MAE******************** 1.1234972476959229\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4910 - mae: 0.5111 - mse: 0.4910 - val_loss: 0.5903 - val_mae: 0.5399 - val_mse: 0.5903\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4908 - mae: 0.5110 - mse: 0.4908 - val_loss: 0.5868 - val_mae: 0.5399 - val_mse: 0.5868\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.1284210681915283\n",
      "************MAE******************** 1.124629259109497\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4843 - mae: 0.5074 - mse: 0.4843 - val_loss: 0.5821 - val_mae: 0.5353 - val_mse: 0.5821\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4778 - mae: 0.5009 - mse: 0.4778 - val_loss: 0.5748 - val_mae: 0.5442 - val_mse: 0.5748\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.1420881748199463\n",
      "************MAE******************** 1.1313738822937012\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.1244852542877197\n",
      "************MAE******************** 1.1255003213882446\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.4692 - mae: 0.4976 - mse: 0.4692 - val_loss: 0.5681 - val_mae: 0.5233 - val_mse: 0.5681\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4687 - mae: 0.4985 - mse: 0.4687 - val_loss: 0.5608 - val_mae: 0.5402 - val_mse: 0.5608\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "*************LOSS****************** 2.13070011138916\n",
      "************MAE******************** 1.1263831853866577\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.4633 - mae: 0.4926 - mse: 0.4633 - val_loss: 0.5585 - val_mae: 0.5230 - val_mse: 0.5585\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4605 - mae: 0.4908 - mse: 0.4605 - val_loss: 0.5545 - val_mae: 0.5223 - val_mse: 0.5545\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "*************LOSS****************** 2.12174916267395\n",
      "************MAE******************** 1.1231682300567627\n",
      "Epoch 1/2\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4569 - mae: 0.4885 - mse: 0.4569 - val_loss: 0.5538 - val_mae: 0.5203 - val_mse: 0.5538\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4561 - mae: 0.4902 - mse: 0.4561 - val_loss: 0.5481 - val_mae: 0.5334 - val_mse: 0.5481\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "*************LOSS****************** 2.157604455947876\n",
      "************MAE******************** 1.139198660850525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-11-23 01:46:33,099 | connection.py:139 | gRPC channel closed\n",
      "INFO flwr 2023-11-23 01:46:33,102 | app.py:215 | Disconnect and shut down\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = ut.partition_dataset(0,4,1)\n",
    "\n",
    "client = CifarClient(get_model(), x_train, y_train, x_test, y_test)\n",
    "\n",
    "history = fl.client.start_numpy_client(\n",
    "server_address=\"127.0.0.1:8082\",\n",
    "client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = ut.partition_dataset(-2,4,1)\n",
    "\n",
    "client = CifarClient(get_model(), x_train, y_train, x_test, y_test)\n",
    "\n",
    "history = fl.client.start_numpy_client(\n",
    "server_address=\"127.0.0.1:8082\",\n",
    "client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
